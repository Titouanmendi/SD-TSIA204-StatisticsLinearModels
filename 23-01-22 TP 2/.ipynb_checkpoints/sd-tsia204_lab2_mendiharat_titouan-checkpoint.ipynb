{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compte rendu Titouan Mendiharat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.model_selection import KFold\n",
    "from numpy.linalg import inv\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy import stats\n",
    "from scipy.stats import t\n",
    "from sklearn.linear_model import ElasticNet\n",
    "import seaborn as sns\n",
    "import warnings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.reset_defaults()\n",
    "sns.set(style='darkgrid', palette = 'colorblind')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Set the seed to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed to 0\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Load the data. Print the mean, and standard deviation of every covariate. Is the data centered? Normalized? Standardized?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN\n",
      "V1       2.808561\n",
      "V2       2.811137\n",
      "V3       2.813727\n",
      "V4       2.816363\n",
      "V5       2.819098\n",
      "          ...    \n",
      "V97      3.081070\n",
      "V98      3.062290\n",
      "V99      3.043548\n",
      "V100     3.024895\n",
      "fat     18.142326\n",
      "Length: 101, dtype: float64\n",
      " \n",
      "STANDARD DEVIATION\n",
      "V1       0.410793\n",
      "V2       0.413352\n",
      "V3       0.415906\n",
      "V4       0.418465\n",
      "V5       0.421040\n",
      "          ...    \n",
      "V97      0.539730\n",
      "V98      0.538586\n",
      "V99      0.537108\n",
      "V100     0.535354\n",
      "fat     12.740297\n",
      "Length: 101, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Load the data in a dataframe\n",
    "data = pd.read_csv('meatspec.csv')\n",
    "\n",
    "# Compute the mean and standard deviation\n",
    "mean = data.mean()\n",
    "std = data.std()\n",
    "\n",
    "# Print the results\n",
    "print('MEAN')\n",
    "print(mean)\n",
    "print (' ')\n",
    "print('STANDARD DEVIATION')\n",
    "print(std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first printed the mean of every column then its standard deviation. Since the mean isn't equal to 0, the data isn't centered. Therefore is cannot be nomalized or standardized neither (plus the standard deviation isn't equal to 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Separate the data in train and test sets and standardize both of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the data from the expected results\n",
    "X = data.drop(data.columns[-1], axis=1)\n",
    "y = data.iloc[:, -1]\n",
    "\n",
    "# Divide X and y into train and test sets\n",
    "Xbase_train, Xbase_test, ybase_train, ybase_test = train_test_split(X, y, test_size = 0.25, random_state=0)\n",
    "\n",
    "# Standardize the sets\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(Xbase_train)\n",
    "X_test = scaler.transform(Xbase_test)\n",
    "y_train = scaler.fit_transform(np.array(ybase_train).reshape(-1,1)).flatten()\n",
    "y_test = scaler.transform(np.array(ybase_test).reshape(-1,1)).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) Fit a regular OLS, do we need to fit the intercept?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Predict the results\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No, we don't need to fit the intercept since our data is standardized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e) Create a dataFrame df_coef and store the R2 coefficients of the estimated model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R2 coefficient is : 0.9600547777928068\n"
     ]
    }
   ],
   "source": [
    "# Compute the r2 coefficients and put them in a dataframe\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "df_coef = pd.DataFrame({'OLS': [r2]})\n",
    "\n",
    "# Print the results\n",
    "print(\"The R2 coefficient is : {}\".format(r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_columns = X.columns\n",
    "X_train_index = Xbase_train.index\n",
    "X_train_df = pd.DataFrame(X_train, columns=X_train_columns.to_numpy(), index=X_train_index)\n",
    "y_train_df = pd.DataFrame(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40, 7, 39, 6, 41, 8, 38, 5, 42, 9, 37, 4, 36, 10, 97, 3, 43, 11, 35, 2, 96, 12, 98, 13, 34, 1, 44, 0, 95, 14, 33, 15, 99, 16, 32, 17, 94, 18, 93, 19, 45, 64, 31, 65, 92, 63, 91, 66, 90, 67, 30, 20, 89, 62, 88, 68, 46, 61, 87, 69, 86, 60, 85, 53, 29, 52, 84, 70, 83, 54, 28, 59, 82, 21, 47, 55, 81, 58, 27, 51, 80, 71, 26, 56, 79, 57, 48, 72, 78, 50, 25, 22, 77, 73, 24, 74, 76, 75, 49, 23]\n",
      "[8.215650382226158e-15, 0.02082905738668339, 0.02065632626606395, 0.01968344635480279, 0.0203679059564561, 0.019602206734373073, 0.0204806368504149, 0.01976466576605662, 0.02386510588665125, 0.02329364570614878, 0.023193373244933646, 0.02281261394388645, 0.030176737718904834, 0.02951220198796034, 0.03338122069829663, 0.037672203111861924, 0.0347599753703518, 0.034169208076720636, 0.03840943774444594, 0.039607509306966326, 0.04377752524085721, 0.0475645542714942, 0.05208141917750564, 0.06063164962214529, 0.05593828156454883, 0.05561124286793406, 0.06833730520847237, 0.07238025952410632, 0.07647607298416115, 0.0833745632070868, 0.080058820963679, 0.08769408341250484, 0.10056066391042529, 0.12059159872882064, 0.1320410445260547, 0.14861251856240743, 0.1531240748431717, 0.18485897388294714, 0.20936517419152878, 0.2506713969364134, 0.2561000373994049, 0.2603959204925874, 0.2710434976582725, 0.27854040524030643, 0.2872627976823907, 0.2912547658294673, 0.32009132951198804, 0.32330664243943463, 0.35264666815865375, 0.3570254056281805, 0.37834550659622246, 0.3729116915437245, 0.3805807030518904, 0.3886375437522207, 0.4135392715854409, 0.4166349285359532, 0.4299218470728321, 0.43577270998963624, 0.44100626639345597, 0.4463552883282347, 0.4659847576755538, 0.47004093507488864, 0.494184150057128, 0.4969670787830269, 0.4955221862300059, 0.5007755178065694, 0.5285916719361428, 0.5333133292610377, 0.5703061910771161, 0.5724331201450936, 0.6012627322906146, 0.6083498874491267, 0.6191045100626102, 0.6206978211746306, 0.622655503299677, 0.6230391678693623, 0.673130194268607, 0.6756268948534387, 0.6951244852105285, 0.7002718554163825, 0.7258937840540738, 0.7256250671242177, 0.7658689503762166, 0.771664411272833, 0.7740590562911707, 0.77572878348106, 0.7808352348280994, 0.7960599562988762, 0.832347486490395, 0.851963090542581, 0.8605099374783665, 0.8609942934270807, 0.8905190717238773, 0.8902341209449649, 0.9034923002748851, 0.9289019464470254, 0.9458393871310158, 0.9714018471102042, 0.9779142320232566, 0.9779138354523682]\n"
     ]
    }
   ],
   "source": [
    "def p_value(X, y, n, p) :\n",
    "    X=X.reshape(-1,1)\n",
    "    lr = LinearRegression(fit_intercept=False)\n",
    "    lr.fit(X,y)\n",
    "    theta = lr.coef_\n",
    "    s = 1/n * (X.T @ X)\n",
    "    s_inv = np.linalg.inv(s)\n",
    "    y_pred = lr.predict(X)\n",
    "    sigma = 1/(n-2) * (np.linalg.norm(y-y_pred)**2)\n",
    "    T = np.sqrt(n)*np.abs(theta)/(s_inv*sigma)\n",
    "    p_value = 2*(1-t.cdf(T, n-p-1))\n",
    "    return p_value\n",
    "\n",
    "def forward_variable_selection(X,y):\n",
    "    n = X.shape[0]\n",
    "    p = X.shape[1]\n",
    "    r = y\n",
    "    pvals = []\n",
    "    selected_vars = []\n",
    "    A = list(range(p))\n",
    "    for i in range(p) :\n",
    "        bestpval = 10\n",
    "        for j in A :\n",
    "            pval = p_value(X[:,j], r, n, p)[0][0]\n",
    "            if pval < bestpval :\n",
    "                bestpval = pval\n",
    "                bestvar = j\n",
    "        pvals.append(bestpval)\n",
    "        selected_vars.append(bestvar)\n",
    "        A.remove(bestvar)\n",
    "        lr = LinearRegression(fit_intercept=False)\n",
    "        lr.fit(X[:, bestvar].reshape(-1,1), r)\n",
    "        y_pred = lr.predict(X[:, bestvar].reshape(-1,1))\n",
    "        r = r - y_pred\n",
    "    return pvals, selected_vars\n",
    "\n",
    "pvals, features = forward_variable_selection(X_train, y_train)\n",
    "\n",
    "print(features)\n",
    "print(pvals)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### a) Apply the OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coefficients of the model are [ 59233.12114515 -27540.50468385 -25637.25225839  37597.02996794\n",
      " -74189.42157703  22634.26577694   8448.73239003 -45669.33475007\n",
      "  46952.83227049  -8320.1266037   -4927.90914278  25308.10793762\n",
      "   6972.50691421  -2001.29909442   -122.98368206   1700.88512346\n",
      " -12133.2037682   13079.81008287  -4710.46849607  -5828.4135057\n",
      "    111.93951273 -10959.33652463].\n"
     ]
    }
   ],
   "source": [
    "# Select the variables whose p_value is < 0.05\n",
    "selected_var = []\n",
    "selected_indexes = []\n",
    "for i in range(len(features)) :\n",
    "    if pvals[i] < 0.05 :\n",
    "        selected_var.append(\"V{}\".format(features[i]))\n",
    "        selected_indexes.append(features[i])\n",
    "\n",
    "# Apply the OLS to the selected set\n",
    "X_selected = X[selected_var]\n",
    "model.fit(X_selected, y)\n",
    "model.predict(X_selected)\n",
    "\n",
    "# Print the results\n",
    "print(\"The coefficients of the model are {}.\".format(model.coef_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Store the R2 coefficient in df_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Its R2 coefficient is : 0.9601005203234244\n",
      " \n",
      "        OLS  OLS with variable selection\n",
      "0  0.960055                     0.960101\n"
     ]
    }
   ],
   "source": [
    "# Store the r2 coefficient in df_coef\n",
    "df_coef['OLS with variable selection'] = model.score(X_selected, y)\n",
    "\n",
    "# Print it\n",
    "print(\"Its R2 coefficient is : {}\".format(model.score(X_selected, y)))\n",
    "print(' ')\n",
    "print(df_coef)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  3  7 18 19 21 34 39 40 44 45 46 47 48 49 57 74 87 90 97 99]\n",
      "['V10' 'V11' 'V12' 'V2' 'V3' 'V35' 'V36' 'V37' 'V38' 'V39' 'V4' 'V40'\n",
      " 'V41' 'V42' 'V43' 'V5' 'V6' 'V7' 'V8' 'V9' 'V96' 'V97']\n"
     ]
    }
   ],
   "source": [
    "reg = LinearRegression().fit(X_train, y_train)\n",
    "sfs = SequentialFeatureSelector(reg, n_features_to_select=len(selected_var))\n",
    "sfs.fit(X_train,y_train)\n",
    "print(sfs.get_support(indices=True)) #gives index from selected optimal features\n",
    "print(np.sort(selected_var)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2coeff(y, y_pred) :\n",
    "    mean = y.mean()\n",
    "    sum1 = 0\n",
    "    sum2 = 0\n",
    "    for i in range(len(y)-1) :\n",
    "        sum1 = sum1 + (y.loc[i]-y_pred[i])**2\n",
    "        sum2 = sum2 +(y.loc[i]-mean)**2\n",
    "    r2 = 1-(sum1/sum2)\n",
    "    return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2coeff_np(y, y_pred) :\n",
    "    mean = y.mean()\n",
    "    sum1 = 0\n",
    "    sum2 = 0\n",
    "    for i in range(len(y)-1) :\n",
    "        sum1 = sum1 + (y[i]-y_pred[i])**2\n",
    "        sum2 = sum2 +(y[i]-mean)**2\n",
    "    r2 = 1-(sum1/sum2)\n",
    "    return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        OLS  OLS with variable selection       SFS\n",
      "0  0.960055                     0.960101  0.948842\n",
      " \n",
      "R2 for the test data: 0.9488417598419069\n"
     ]
    }
   ],
   "source": [
    "# Test and train data with selected variables of method 2\n",
    "m = len(sfs.get_support(indices=True))\n",
    "n1 = len(X_train)\n",
    "n2 = len(X_test)\n",
    "X_train_selected_2 = np.zeros((n1, m))\n",
    "X_test_selected_2 = np.zeros((n2, m))\n",
    "\n",
    "for j, row in enumerate(selected_indexes):\n",
    "    X_train_selected_2[:, j] = X_train[:, row]\n",
    "    X_test_selected_2[:, j] = X_test[:, row]\n",
    "\n",
    "# OLS regression on X with selected variablesof method 2\n",
    "reg_method_2 = LinearRegression().fit(X_train_selected_2, y_train)\n",
    "y_pred = reg_method_2.predict(X_test_selected_2)\n",
    "\n",
    "#store R2 in the data frame \n",
    "df_coef['SFS'] = r2coeff_np(y_pred, y_test)\n",
    "print(df_coef.head())\n",
    "print(' ')\n",
    "print(\"R2 for the test data:\", r2coeff_np(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Plot how the values of the coefficients change with α."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our own ridge function\n",
    "def ridge(X, y, a) :\n",
    "    n = X.shape[1]\n",
    "    estimator = inv(((X.T)@X + n*a*np.eye(n)))@(X.T)@y\n",
    "    return estimator\n",
    "\n",
    "# Define the list of the alphas\n",
    "\n",
    "alphas = np.logspace(-9, 2, num=100, base=10)\n",
    "\n",
    "# For each alpha, compute the ridge and store it in a list\n",
    "estimatorlist = []\n",
    "for i in alphas :\n",
    "    estimatorlist.append(ridge(X_train, y_train, i))\n",
    "\n",
    "list_values = []\n",
    "for i in range(len(estimatorlist[0])) :\n",
    "    val = []\n",
    "    for j in range(len(estimatorlist)) :\n",
    "        val.append(estimatorlist[j][i])\n",
    "    list_values.append(val)\n",
    "\n",
    "# Log scale\n",
    "abs = np.arange(-9, 2, 1)\n",
    "\n",
    "plt.figure()\n",
    "plt.legend()\n",
    "plt.xscale('log')\n",
    "plt.xlabel(\"Alphas\")\n",
    "plt.ylabel(\"Value of the coefficients\")\n",
    "# Plot the results\n",
    "for i in range(len(list_values)-1) :\n",
    "    plt.plot(alphas, list_values[i])\n",
    "plt.title(\"Estimator depending on the penalty parameter alpha with a log scale 10e-9 to 10e2\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Plot how MSE of both the train and test sets change with α. Signal the minimum with a point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mse = []\n",
    "test_mse = []\n",
    "\n",
    "for i in alphas :\n",
    "    estimator = ridge(X_train, y_train, i)\n",
    "    y_pred_train = np.dot(X_train, estimator)\n",
    "    y_pred_test = np.dot(X_test, estimator)\n",
    "    mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "    mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "    train_mse.append(mse_train)\n",
    "    test_mse.append(mse_test)\n",
    "\n",
    "plt.xlabel(\"Alphas\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.xscale('log')\n",
    "plt.plot(alphas, train_mse, label =\"Train MSE\")\n",
    "plt.plot(alphas, test_mse, label=\"Test MSE\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Store the r2 coefficient for the best alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the previous graphic, the MSE is non decreasing. Therefore, the best alpha is $10^{-9}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 10**(-9)\n",
    "rdg = ridge(X_train, y_train, a)\n",
    "y_pred_test = np.dot(X_test, rdg)\n",
    "r2 = r2coeff_np(y_test, y_pred_test)\n",
    "print(\"The R2 coefficient is : {}\".format(r2))\n",
    "print(' ')\n",
    "\n",
    "df_coef['Ridge'] = r2\n",
    "\n",
    "print(df_coef.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation, Lasso and elastic net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Elaborate on why these warning arise and on the solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tol parameter (which stands for tolerance) controls the stopping criterion for the algorithm. If it is set too high, the algorithm may not converge to the optimal solution. Therefore, it may continue running until max_iter is reached, raising a warning.\\\n",
    "To avoid this, you can either decrease the tolerance or increase the maximum number of iterations.\\\n",
    "Decreasing tol will make the algorithm more strict in determining when to stop the optimization process, thus reducing the chances of the algorithm not converging. On the other hand, increasing the maximum number of iterations allows the algorithm more time to find the optimal solution, which can also help to reduce the chances of the algorithm not converging. However, I could run for too long even though it is not necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Plot the number of coefficients that are different from 0 for each value of α"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the list of alphas\n",
    "alphas2 = np.logspace(-6, -2, num=100, base=10)\n",
    "    \n",
    "\n",
    "# Define the log-scale that we'll use to plot\n",
    "abs2 = np.arange(-5, -1, 1)\n",
    "\n",
    "# Define and fill the list of the lasso\n",
    "lasso_list = []\n",
    "nb_coef_not_0 = []\n",
    "for a in alphas2 :\n",
    "    incr = 0\n",
    "    las = Lasso(a, tol=0.05, max_iter=20000)\n",
    "    las.fit(X_train, y_train)\n",
    "    for i in las.coef_ :\n",
    "        if i==0 :\n",
    "            incr+=1\n",
    "    nb_coef_not_0.append(len(las.coef_)-incr)\n",
    "    lasso_list.append(las)\n",
    "\n",
    "plt.plot(alphas2, nb_coef_not_0)\n",
    "plt.title(\"Number of coefficients different to zero in function of alpha\")\n",
    "plt.xlabel(\"Alphas\")\n",
    "plt.ylabel(\"Number of coefficients\")\n",
    "plt.xscale('log')\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Plot how MSE of both the train and test sets change with α. Signal the minimum with a point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mse2 = []\n",
    "test_mse2 = []\n",
    "\n",
    "for las in lasso_list :\n",
    "    y_pred_train = las.predict(X_train)\n",
    "    y_pred_test = las.predict(X_test)\n",
    "    train_mse2.append(mean_squared_error(y_train, y_pred_train))\n",
    "    test_mse2.append(mean_squared_error(y_test, y_pred_test))\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.plot(alphas2, train_mse2, label = \"train\")\n",
    "plt.plot(alphas2, test_mse2, label = \"test\")\n",
    "plt.legend()\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) For the best performing value of α on the test set store the R2 results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso(10**(-3), tol=0.05, max_iter=20000)\n",
    "lasso.fit(X_test, y_test)\n",
    "y_pred = lasso.predict(X_test)\n",
    "r2_test_best = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"The r2 coefficient obtained is : {} \".format(r2_test_best))\n",
    "\n",
    "df_coef['Lasso'] = r2_test_best\n",
    "print(df_coef.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore Lasso warnings\n",
    "warnings.filterwarnings('ignore', module='sklearn.linear_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_cross_val_score(X, y, model, splits=5):\n",
    "    kf = KFold(n_splits=splits, shuffle=True)\n",
    "    scores = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train_cv, X_test_cv = X.loc[train_index], X.loc[test_index]\n",
    "        y_train_cv, y_test_cv = y.loc[train_index], y.loc[test_index]\n",
    "        model.fit(X_train_cv, y_train_cv)\n",
    "        score = model.score(X_test_cv, y_test_cv)\n",
    "        scores.append(score)\n",
    "    return np.array(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the ElasticNet model\n",
    "enet = ElasticNet(alpha=0.1, l1_ratio=0.5)\n",
    "\n",
    "# Calculate the cross-validation scores\n",
    "scores = custom_cross_val_score(X, y, enet)\n",
    "print(\"List of R2 scores : {}\".format(scores))\n",
    "print(' ')\n",
    "\n",
    "# Calculate the mean and standard deviation of the scores\n",
    "mean_score = np.mean(scores)\n",
    "std_score = np.std(scores)\n",
    "\n",
    "print(\"Mean of the list : {}\".format(mean_score))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_cross_val_score_ridge(X, y, a, splits=5):\n",
    "    kf = KFold(n_splits=splits, shuffle=True)\n",
    "    scores = []\n",
    "    y = y.to_numpy()\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train_cv, X_test_cv = X.loc[train_index], X.loc[test_index]\n",
    "        y_train_cv = y[train_index]\n",
    "        y_test_cv = y[test_index]\n",
    "        rdg = ridge(X_train_cv, y_train_cv, a)\n",
    "        y_pred_test = np.dot(X_test_cv, rdg)\n",
    "        r2 = r2coeff_np(y_test_cv, y_pred_test)\n",
    "        scores.append(r2)\n",
    "    return np.array(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_las = [0, 0.1, 0.5, 0.7, 0.9, 0.95, 0.99]\n",
    "alphas_rdg = np.logspace(-10, 3, num=20, base=10)\n",
    "\n",
    "las_mean = []\n",
    "for a in alpha_las :\n",
    "    las = Lasso(a, tol=0.05, max_iter=20000)\n",
    "    scores_las = custom_cross_val_score(X, y, las)\n",
    "    las_mean.append(np.mean(scores_las))\n",
    "las_score = np.array(las_mean)\n",
    "\n",
    "rdg_mean = []\n",
    "for a in alphas_rdg :\n",
    "    scores_rdg = custom_cross_val_score_ridge(X, y, a)\n",
    "    rdg_mean.append(np.mean(scores_rdg))\n",
    "rdg_score = np.array(rdg_mean)\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "ax1 = plt.subplot(1, 2, 1)\n",
    "ax1.plot(alpha_las, las_score)\n",
    "ax1.set_title(\"Lasso's average r2 depending on alpha\")\n",
    "\n",
    "ax2 = plt.subplot(1, 2, 2)\n",
    "ax2.plot(alphas_rdg, rdg_score)\n",
    "ax2.set_xscale('log')\n",
    "ax2.set_title(\"Ridge's average r2 depending on alpha\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the ridge and lasso work better for the smaller alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract variable 40 from the original dataset X\n",
    "X_40 = X.iloc[:, 39]\n",
    "X_40 = X_40.to_numpy()\n",
    "\n",
    "# Fit a linear regression model to the data\n",
    "reg = LinearRegression().fit(X_40.reshape(-1, 1), y)\n",
    "\n",
    "# Plot the data and the regression line\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(X_40, y)\n",
    "ax.plot(X_40, reg.predict(X_40.reshape(-1, 1)), color='red')\n",
    "ax.set_xlabel('Variable 40')\n",
    "ax.set_ylabel('Target variable')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bootstraps = 50\n",
    "bootstrapped_predictions = []\n",
    "\n",
    "for i in range(n_bootstraps):\n",
    "    sample_indices = np.random.choice(len(X_40), len(X_40), replace=True)\n",
    "    x_sample = X_40[sample_indices]\n",
    "    y_sample = y[sample_indices]\n",
    "    coeffs = np.polyfit(x_sample, y_sample, 1)\n",
    "    y_pred = np.polyval(coeffs, X_40)\n",
    "    \n",
    "    # plot the estimated regression line\n",
    "    plt.plot(X_40, y_pred, color='gray', alpha=0.2)\n",
    "    \n",
    "    # calculate prediction interval\n",
    "    y_pred_sample = np.polyval(coeffs, x_sample)\n",
    "    sigma2 = np.sum((y_pred_sample - y_sample) ** 2) / (len(x_sample) - 2)\n",
    "    sigma = np.sqrt(sigma2)\n",
    "    t = stats.t.ppf(0.975, len(x_sample) - 2)\n",
    "    y_err = t * sigma * np.sqrt(1 + 1 / len(X_40) + (X_40 - np.mean(x_sample)) ** 2 / np.sum((x_sample - np.mean(x_sample)) ** 2))\n",
    "    bootstrapped_predictions.append(y_pred)\n",
    "    #plt.plot(y_pred - y_err, y_pred, color='orange', alpha=0.2)\n",
    "    #plt.plot(y_pred + y_err, y_pred, color='orange', alpha=0.2)\n",
    "    plt.fill_between(X_40,y_pred - y_err, y_pred + y_err, alpha=0.02, color='orange')\n",
    "    \n",
    "plt.scatter(X_40, y, s=10, color='blue')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Plot a heatmap of the covariance matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cov = (X_train.T @ X_train)/len(X_train)\n",
    "cov = np.cov(X_train, rowvar=False)\n",
    "sns.heatmap(data=cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Do a PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U, s, V = np.linalg.svd(X_cov)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_std = scaler.fit_transform(X)\n",
    "\n",
    "# compute the projection of the data onto the principal components\n",
    "PC = np.dot(X_train, U[:, :2])\n",
    "\n",
    "# plot the data projected onto the first two principal components\n",
    "\n",
    "plt.scatter(PC[:, 0], PC[:, 1])\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Plot the amount of variance explained by the first k components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = X_train.shape[1]\n",
    "S = np.diag(s)\n",
    "su = []\n",
    "sum = 0\n",
    "fi = 0\n",
    "for k in range(0, p) :\n",
    "    sum += S[k][k]\n",
    "\n",
    "for i in range(2, p) :\n",
    "    for j in range(0, i-1) :\n",
    "        fi += S[j][j]/sum\n",
    "    su.append(fi)\n",
    "    fi = 0\n",
    "\n",
    "plt.plot([k for k in range(2,p)], su)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) Plot the projected data using as color the value of y and interpret the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the data projected onto the first two principal components\n",
    "plt.scatter(PC[:, 0], PC[:, 1], c=y_train)\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e) Run OLS on the projected data using k components for k evenly spaced in 2..p. Store the best score in the dataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the range of k\n",
    "k_range = range(2, p+1)\n",
    "\n",
    "# initialize a list to store the scores\n",
    "scores = []\n",
    "\n",
    "# loop over the values of k\n",
    "for k in k_range:\n",
    "    # project the data onto the first k principal components\n",
    "    PC = np.dot(X_std, U[:, :k])\n",
    "    \n",
    "    # split the data into training and testing sets\n",
    "    X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(PC, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # fit an OLS model to the training data\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_2, y_train_2)\n",
    "    \n",
    "    # evaluate the model on the testing data and store the score\n",
    "    score = model.score(X_test_2, y_test_2)\n",
    "    scores.append(score)\n",
    "\n",
    "# find the best score and corresponding value of k\n",
    "best_score = max(scores)\n",
    "best_k = k_range[scores.index(best_score)]\n",
    "print(f\"Best score: {best_score:.3f}\")\n",
    "print(f\"Best k: {best_k}\")\n",
    "print(' ')\n",
    "df_coef['PCA'] = best_score\n",
    "print(df_coef.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparaison of the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coef.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to our results, it appears that the PCA is the model with most success since it has the highest R2 coefficient. Hence, it is the best model to use in this case."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "09b65ccb47121184b777eb75dc58d45c2e3a6de6a652e90ceaf4c7bcb4f62c8a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
